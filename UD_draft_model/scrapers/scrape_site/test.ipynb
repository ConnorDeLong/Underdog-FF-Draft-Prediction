{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from UD_draft_model.scrapers.scrape_site.pull_bearer_token import pull_bearer_token\n",
    "\n",
    "\n",
    "class BaseData:\n",
    "    def __init__(self, clear_json_attrs: bool=True, slate_id: str=None):\n",
    "        self._clear_json_attrs = clear_json_attrs\n",
    "\n",
    "        if slate_id is None:\n",
    "            # self.slate_id = '87a5caba-d5d7-46d9-a798-018d7c116213'\n",
    "            self.slate_id = \"f659a9be-fd34-4a1e-9c43-0816267e603d\"\n",
    "        else:\n",
    "            self.slate_id = slate_id\n",
    "\n",
    "        # user-agent and/or accept headers sometimes required\n",
    "        self.auth_header = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) \\\n",
    "                                AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                                Chrome/99.0.4844.51 Safari/537.36\",\n",
    "        }\n",
    "\n",
    "        self._player_scores_wk_1_id = 78\n",
    "        self._player_scores_wk_last_id = 78 + 17\n",
    "\n",
    "    def build_all_dfs(self, sleep_time: int=0):\n",
    "        \"\"\"\n",
    "        Overwrites every 'df_' attribute with a df that is created by running the\n",
    "        'create_' method that matches it. This serves as the primary method\n",
    "        for building the dfs associated with the class\n",
    "        \"\"\"\n",
    "\n",
    "        attrs = [attr for attr in dir(self) if attr.startswith(\"df_\")]\n",
    "        for attr in attrs:\n",
    "            method_name = \"create_\" + attr\n",
    "            self.__dict__[attr] = getattr(self, method_name)()\n",
    "            try:\n",
    "                self.__dict__[attr] = getattr(self, method_name)()\n",
    "            except:\n",
    "                print(getattr(self, method_name), \"failed to run\")\n",
    "\n",
    "            if sleep_time > 0:\n",
    "                time.sleep(sleep_time)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if self._clear_json_attrs == True:\n",
    "            self.clear_json_attrs()\n",
    "\n",
    "    def clear_json_attrs(self):\n",
    "        \"\"\"\n",
    "        Clears all the atttributes that hold the json data pulled from the API.\n",
    "        By default, this is executed when the build_all_dfs method is run\n",
    "        \"\"\"\n",
    "\n",
    "        attrs = [attr for attr in dir(self) if attr.startswith(\"json\")]\n",
    "        for attr in attrs:\n",
    "            self.__dict__[attr] = {}\n",
    "\n",
    "    def read_in_site_data(self, url, headers: dict=None) -> dict:\n",
    "        \"\"\"Pulls in the raw data from the API and returns it as a dict\"\"\"\n",
    "\n",
    "        if headers is None:\n",
    "            headers = {}\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        site_data = response.json()\n",
    "\n",
    "        return site_data\n",
    "\n",
    "    def create_scraped_data_df(self, scraped_data: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts a list of dictionaries into a df where the keys of the dicts are\n",
    "        used for the columns and the values are placed in the rows.\n",
    "        NOTE: this assumes the keys in all dicts are the same.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the dicionary keys to identify the columns of the list for each output dict key\n",
    "        output_data_cols = []\n",
    "        for output_data_col in scraped_data[0].keys():\n",
    "            output_data_cols.append(output_data_col)\n",
    "\n",
    "        final_data_dict = {\"columns\": output_data_cols}\n",
    "        for data_dict_id, data in enumerate(scraped_data):\n",
    "            all_data_elements = []\n",
    "            for output_data_col in output_data_cols:\n",
    "                try:\n",
    "                    data_element = data[output_data_col]\n",
    "                except:\n",
    "                    # Note: This should probably be conditional on the data type, \n",
    "                    # but just using N/A for now.\n",
    "                    data_element = \"N/A\"\n",
    "\n",
    "                all_data_elements.append(data_element)\n",
    "\n",
    "            final_data_dict[data_dict_id] = all_data_elements\n",
    "\n",
    "        final_data_df = self._convert_data_dict_to_df(final_data_dict)\n",
    "\n",
    "        return final_data_df\n",
    "\n",
    "    def _convert_data_dict_to_df(self, scraped_data_dict: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts the dict from the create_scraped_data_dict function to a df\n",
    "        NOTE: The input dict takes the following form:\n",
    "        {'columns': [<column names>], 1: [<column values>], 2: [<column_values>], ...}\n",
    "        \"\"\"\n",
    "\n",
    "        columns = scraped_data_dict[\"columns\"]\n",
    "\n",
    "        data_keys = list(scraped_data_dict.keys())[1:]\n",
    "\n",
    "        data_for_df = []\n",
    "        for data_key in data_keys:\n",
    "            data = scraped_data_dict[data_key]\n",
    "\n",
    "            data_for_df.append(data)\n",
    "\n",
    "        final_df = pd.DataFrame(data=data_for_df, columns=columns)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def _create_week_id_mapping(self) -> pd.DataFrame:\n",
    "        \"\"\"Creates a map between the APIs Week ID and the actual Week number\"\"\"\n",
    "\n",
    "        wk_numbers = []\n",
    "        wk_ids = []\n",
    "        for wk_number, wk_id in enumerate(\n",
    "            range(self._player_scores_wk_1_id, self._player_scores_wk_last_id + 1)\n",
    "        ):\n",
    "            wk_numbers.append(wk_number + 1)\n",
    "            wk_ids.append(wk_id)\n",
    "\n",
    "        mapping = {\"week_number\": wk_numbers, \"week_id\": wk_ids}\n",
    "        df_mapping = pd.DataFrame(data=mapping)\n",
    "\n",
    "        return df_mapping\n",
    "\n",
    "\n",
    "class ReferenceData(BaseData):\n",
    "    \"\"\"Compiles all major reference data into dataframes\"\"\"\n",
    "\n",
    "    def __init__(self, clear_json_attrs: bool = True, slate_id: str = None):\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs, slate_id=slate_id)\n",
    "\n",
    "        # week ID seems right but can't find the correct url for it\n",
    "        # self._player_scores_wk_1_id = 78\n",
    "        self._player_scores_wk_1_id = 1186\n",
    "\n",
    "        self.url_players = (\n",
    "            \"https://stats.underdogfantasy.com/v1/slates/\" + self.slate_id + \"/players\"\n",
    "        )\n",
    "        self.url_appearances = (\n",
    "            \"https://stats.underdogfantasy.com/v1/slates/\"\n",
    "            + self.slate_id\n",
    "            + \"/scoring_types/ccf300b0-9197-5951-bd96-cba84ad71e86/appearances\"\n",
    "        )\n",
    "        self.url_teams = \"https://stats.underdogfantasy.com/v1/teams\"\n",
    "\n",
    "        base_url_player_scores = \"https://stats.underdogfantasy.com/v1/weeks/\"\n",
    "        end_url_player_scores = (\n",
    "            \"/scoring_types/ccf300b0-9197-5951-bd96-cba84ad71e86/appearances\"\n",
    "        )\n",
    "        self.urls_player_scores = {\n",
    "            \"player_scores_wk_\"\n",
    "            + str(i + 1): base_url_player_scores\n",
    "            + str(wk_id)\n",
    "            + end_url_player_scores\n",
    "            for i, wk_id in enumerate(\n",
    "                range(self._player_scores_wk_1_id, self._player_scores_wk_1_id + 17)\n",
    "            )\n",
    "        }\n",
    "\n",
    "        self.df_players = pd.DataFrame()\n",
    "        self.df_appearances = pd.DataFrame()\n",
    "        self.df_teams = pd.DataFrame()\n",
    "        self.df_players_master = pd.DataFrame()\n",
    "        self.df_player_scores = pd.DataFrame()\n",
    "\n",
    "    def build_all_dfs(self):\n",
    "        attrs = [attr for attr in dir(self) if attr.startswith(\"df_\")]\n",
    "        for attr in attrs:\n",
    "            if attr == \"df_players_master\":\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    method_name = \"create_\" + attr\n",
    "                    self.__dict__[attr] = getattr(self, method_name)()\n",
    "                except:\n",
    "                    print(getattr(self, method_name), \"failed to run\")\n",
    "\n",
    "        # This ensures the dfs it depends on are created\n",
    "        self.df_players_master = self.create_df_players_master()\n",
    "\n",
    "        if self._clear_json_attrs == True:\n",
    "            self.clear_json_attrs()\n",
    "\n",
    "    def create_df_players(self) -> pd.DataFrame:\n",
    "        self.json_players = self.read_in_site_data(\n",
    "            self.url_players, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(self.json_players[\"players\"])\n",
    "        initial_scraped_df.drop([\"image_url\"], axis=1, inplace=True)\n",
    "        initial_scraped_df.rename(columns={\"id\": \"player_id\"}, inplace=True)\n",
    "\n",
    "        return initial_scraped_df\n",
    "\n",
    "    def create_df_appearances(self) -> pd.DataFrame:\n",
    "        self.json_appearances = self.read_in_site_data(\n",
    "            self.url_appearances, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(\n",
    "            self.json_appearances[\"appearances\"]\n",
    "        )\n",
    "        initial_scraped_df.drop(\n",
    "            [\"latest_news_item_updated_at\", \"score\"], axis=1, inplace=True\n",
    "        )\n",
    "\n",
    "        # 'projection' column values are dicitionaries which can be converted to a df and merged\n",
    "        projection_col = initial_scraped_df[\"projection\"].to_list()\n",
    "        projection_df = self.create_scraped_data_df(projection_col)\n",
    "\n",
    "        projection_df.drop([\"id\", \"scoring_type_id\"], axis=1, inplace=True)\n",
    "        projection_df.rename(\n",
    "            columns={\"points\": \"season_projected_points\"}, inplace=True\n",
    "        )\n",
    "\n",
    "        final_df = pd.merge(\n",
    "            initial_scraped_df,\n",
    "            projection_df,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        final_df.drop([\"projection\"], axis=1, inplace=True)\n",
    "\n",
    "        df_pos_map = self._create_position_mapping(final_df)\n",
    "        final_df = pd.merge(final_df, df_pos_map, on=\"position_id\", how=\"left\")\n",
    "\n",
    "        final_df.rename(columns={\"id\": \"appearance_id\"}, inplace=True)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def create_df_teams(self) -> pd.DataFrame:\n",
    "        self.json_teams = self.read_in_site_data(\n",
    "            self.url_teams, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(self.json_teams[\"teams\"])\n",
    "\n",
    "        keep_vars = [\"id\", \"abbr\", \"name\"]\n",
    "        final_df = initial_scraped_df[keep_vars].copy()\n",
    "\n",
    "        final_df.rename(columns={\"name\": \"team_name\", \"id\": \"team_id\"}, inplace=True)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def create_df_players_master(self) -> pd.DataFrame:\n",
    "        \"\"\"Creates a master lookup for player attributes\"\"\"\n",
    "\n",
    "        if len(self.df_appearances) == 0:\n",
    "            self.df_appearances = self.create_df_appearances()\n",
    "\n",
    "        if len(self.df_players) == 0:\n",
    "            self.df_players = self.create_df_players()\n",
    "\n",
    "        if len(self.df_teams) == 0:\n",
    "            self.df_teams = self.create_df_teams()\n",
    "\n",
    "        # Team is more accurate in the df_players data and position from df_appearances\n",
    "        # reflects the posisiton at the time of the draft\n",
    "        df_appearances = self.df_appearances.drop([\"team_id\"], axis=1, inplace=False)\n",
    "        df_players = self.df_players.drop([\"position_id\"], axis=1, inplace=False)\n",
    "\n",
    "        final_df = pd.merge(df_appearances, df_players, on=\"player_id\", how=\"left\")\n",
    "\n",
    "        final_df = pd.merge(final_df, self.df_teams, on=\"team_id\", how=\"left\")\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def create_df_player_scores(self):\n",
    "        \"\"\"\n",
    "        This no longer appears to work due to either a change in the endpoint\n",
    "        or the starting point week id is wrong\n",
    "        \"\"\"\n",
    "\n",
    "        self.json_player_scores = {\n",
    "            \"player_scores_wk_\"\n",
    "            + str(i + 1): self.read_in_site_data(\n",
    "                self.urls_player_scores[\"player_scores_wk_\" + str(i + 1)],\n",
    "                headers=self.auth_header,\n",
    "            )\n",
    "            for i, wk_id in enumerate(\n",
    "                range(self._player_scores_wk_1_id, self._player_scores_wk_1_id + 17)\n",
    "            )\n",
    "        }\n",
    "\n",
    "        player_scores_df_list = []\n",
    "        for wk_id in range(1, 18):\n",
    "            if (\n",
    "                len(\n",
    "                    self.json_player_scores[\"player_scores_wk_\" + str(wk_id)][\n",
    "                        \"appearances\"\n",
    "                    ]\n",
    "                )\n",
    "                > 0\n",
    "            ):\n",
    "                player_scores_json = self.json_player_scores[\n",
    "                    \"player_scores_wk_\" + str(wk_id)\n",
    "                ]\n",
    "                player_scores_df = self._create_df_player_scores_one_wk(\n",
    "                    player_scores_json[\"appearances\"]\n",
    "                )\n",
    "                player_scores_df[\"week_number\"] = wk_id\n",
    "\n",
    "                player_scores_df_list.append(player_scores_df)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        player_scores_df = pd.concat(player_scores_df_list)\n",
    "        player_scores_df.reset_index(inplace=True)\n",
    "\n",
    "        return player_scores_df\n",
    "\n",
    "    def _create_df_player_scores_one_wk(self, scraped_data: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Each weeks player scores are contained in its own URL - this creates a df\n",
    "        of those scores for one week\n",
    "        \"\"\"\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(scraped_data)\n",
    "        initial_scraped_df.drop([\"latest_news_item_updated_at\"], axis=1, inplace=True)\n",
    "\n",
    "        # 'projection' column values are dicitionaries which can be converted to a df and merged\n",
    "        projection_col = initial_scraped_df[\"projection\"].to_list()\n",
    "        projection_df = self.create_scraped_data_df(projection_col)\n",
    "\n",
    "        projection_df = projection_df[[\"points\"]]\n",
    "        projection_df.rename(columns={\"points\": \"projected_points\"}, inplace=True)\n",
    "\n",
    "        score_col = initial_scraped_df[\"score\"].to_list()\n",
    "        score_df = self.create_scraped_data_df(score_col)\n",
    "\n",
    "        score_df = score_df[[\"points\"]]\n",
    "        score_df.rename(columns={\"points\": \"actual_points\"}, inplace=True)\n",
    "\n",
    "        final_df = pd.merge(\n",
    "            initial_scraped_df,\n",
    "            projection_df,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        final_df = pd.merge(\n",
    "            final_df, score_df, left_index=True, right_index=True, how=\"left\"\n",
    "        )\n",
    "\n",
    "        final_df.drop([\"projection\", \"score\"], axis=1, inplace=True)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def _create_position_mapping(self, df_appearances: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates df that maps position to position_id since this cant be found in the API\n",
    "        \"\"\"\n",
    "\n",
    "        df_pos_map = df_appearances.copy()\n",
    "\n",
    "        df_pos_map[\"position\"] = df_pos_map[\"position_rank\"].str[0:2]\n",
    "        df_pos_map = df_pos_map[[\"position_id\", \"position\"]].loc[\n",
    "            df_pos_map[\"position\"].notnull()\n",
    "        ]\n",
    "        df_pos_map = df_pos_map.drop_duplicates(\n",
    "            subset=[\"position\", \"position_id\"], keep=\"first\"\n",
    "        )\n",
    "\n",
    "        return df_pos_map\n",
    "\n",
    "\n",
    "class LeagueData(BaseData):\n",
    "    \"\"\"Compiles all major league specific data into dataframes\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, league_ids: list, bearer_token: str, clear_json_attrs: bool = True\n",
    "    ):\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "\n",
    "        self.url_drafts = {}\n",
    "        self.url_weekly_scores = {}\n",
    "        for league_id in league_ids:\n",
    "            url_draft = \"https://api.underdogfantasy.com/v2/drafts/\" + league_id\n",
    "            url_weekly_scores = (\n",
    "                \"https://api.underdogfantasy.com/v1/drafts/\"\n",
    "                + league_id\n",
    "                + \"/weekly_scores\"\n",
    "            )\n",
    "\n",
    "            self.url_drafts[league_id] = url_draft\n",
    "            self.url_weekly_scores[league_id] = url_weekly_scores\n",
    "\n",
    "        self.json_drafts = {}\n",
    "        self.json_weekly_scores = {}\n",
    "\n",
    "        self.df_drafts = pd.DataFrame()\n",
    "        self.df_weekly_scores = pd.DataFrame()\n",
    "\n",
    "    def create_df_drafts(self) -> pd.DataFrame:\n",
    "        dfs = []\n",
    "        for league_id in self.league_ids:\n",
    "            df = self._create_df_draft_ind_league(league_id)\n",
    "            dfs.append(df)\n",
    "\n",
    "        final_df = pd.concat(dfs)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def create_df_weekly_scores(self) -> pd.DataFrame:\n",
    "        dfs = []\n",
    "        for league_id in self.league_ids:\n",
    "            df = self._create_df_weekly_scores_ind_league(league_id)\n",
    "            dfs.append(df)\n",
    "\n",
    "        final_df = pd.concat(dfs)\n",
    "        final_df.reset_index(inplace=True)\n",
    "\n",
    "        week_mapping = self._create_week_id_mapping()\n",
    "        final_df = pd.merge(final_df, week_mapping, on=\"week_id\")\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def _create_df_draft_ind_league(self, league_id: str) -> pd.DataFrame:\n",
    "        self.json_drafts[league_id] = self.read_in_site_data(\n",
    "            self.url_drafts[league_id], headers=self.auth_header\n",
    "        )\n",
    "        scraped_data = self.json_drafts[league_id][\"draft\"][\"picks\"]\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(scraped_data)\n",
    "        initial_scraped_df.drop([\"projection_average\"], axis=1, inplace=True)\n",
    "\n",
    "        initial_scraped_df[\"draft_id\"] = league_id\n",
    "\n",
    "        return initial_scraped_df\n",
    "\n",
    "    def _create_df_weekly_scores_ind_league(self, league_id: str) -> pd.DataFrame:\n",
    "        self.json_weekly_scores[league_id] = self.read_in_site_data(\n",
    "            self.url_weekly_scores[league_id], headers=self.auth_header\n",
    "        )\n",
    "        scraped_data = self.json_weekly_scores[league_id][\"draft_weekly_scores\"]\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(scraped_data)\n",
    "\n",
    "        weekly_scores = self._pull_out_weekly_scores(initial_scraped_df)\n",
    "\n",
    "        initial_scraped_df.drop([\"week\", \"draft_entries_points\"], axis=1, inplace=True)\n",
    "\n",
    "        final_scraped_df = pd.merge(\n",
    "            left=weekly_scores, right=initial_scraped_df, on=\"id\", how=\"left\"\n",
    "        )\n",
    "        final_scraped_df.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "        return final_scraped_df\n",
    "\n",
    "    def _pull_out_weekly_scores(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Each row represents one week where each teams score is contained\n",
    "        within a dicitonary for that week. This pulls those scores out and\n",
    "        puts them in a Team/Week level df\n",
    "        \"\"\"\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        all_weekly_scores = []\n",
    "        for index, row in df.iterrows():\n",
    "            row_id = row[\"id\"]\n",
    "            week_id = row[\"week\"][\"id\"]\n",
    "            status = row[\"week\"][\"status\"]\n",
    "            points_dict = row[\"draft_entries_points\"]\n",
    "\n",
    "            for user_id, points in points_dict.items():\n",
    "                weekly_scores = [row_id, week_id, status, user_id, points]\n",
    "\n",
    "                all_weekly_scores.append(weekly_scores)\n",
    "\n",
    "        columns = [\"id\", \"week_id\", \"status\", \"user_id\", \"total_points\"]\n",
    "        df = pd.DataFrame(data=all_weekly_scores, columns=columns)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class UserData(BaseData):\n",
    "    \n",
    "    def __init__(self, bearer_token: str, clear_json_attrs: bool = True):\n",
    "        \"\"\"\n",
    "        Note: This requires the user-agent header - Should be able to grab this\n",
    "        with the bearer token, but hard coding for now\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "\n",
    "        self.slate_id = '87a5caba-d5d7-46d9-a798-018d7c116213'\n",
    "\n",
    "        self.url_live_leagues = (\n",
    "            'https://api.underdogfantasy.com/v3/user/active_drafts'\n",
    "        )\n",
    "        # self.url_base_leagues = (\n",
    "        #     \"https://api.underdogfantasy.com/v2/user/slates/\"\n",
    "        #     + self.slate_id\n",
    "        #     + \"/live_drafts\"\n",
    "        # )\n",
    "        # self.url_base_leagues = (\n",
    "        #     'https://api.underdogfantasy.com/v2/user/slates/' \n",
    "        #     + self.slate_id \n",
    "        #     + '/completed_drafts'\n",
    "        # )\n",
    "        self.url_base_leagues = (\n",
    "            'https://api.underdogfantasy.com/v2/user/slates/' \n",
    "            + self.slate_id \n",
    "            + '/settled_drafts'\n",
    "        )\n",
    "        self.url_tourney_league_ids = (\n",
    "            \"https://api.underdogfantasy.com/v1/user/slates/\"\n",
    "            + self.slate_id\n",
    "            + \"/tournament_rounds\"\n",
    "        )\n",
    "\n",
    "        self.json_leagues = {}\n",
    "\n",
    "        self.df_all_leagues = pd.DataFrame()\n",
    "\n",
    "    def create_df_all_leagues(self, league_urls: list=None) -> pd.DataFrame:\n",
    "        if league_urls is None:\n",
    "            league_urls = self._create_league_urls()\n",
    "\n",
    "        leagues = []\n",
    "        for i, league_url in enumerate(league_urls):\n",
    "            df = self._create_df_leagues(league_url, \"league_\" + str(i + 1))\n",
    "            leagues.append(df)\n",
    "\n",
    "        df_all_leagues = pd.concat(leagues)\n",
    "        df_all_leagues.reset_index(inplace=True)\n",
    "        df_all_leagues.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "        return df_all_leagues\n",
    "\n",
    "    def _create_df_leagues(self, url_base: str, json_leagues_key: str) -> pd.DataFrame:\n",
    "        self.json_leagues[json_leagues_key] = self._create_json_leagues(url_base)\n",
    "        scraped_data = self.json_leagues[json_leagues_key]\n",
    "\n",
    "        leagues_df_list = []\n",
    "        for leagues_page in scraped_data.values():\n",
    "            leagues_page_df = self.create_scraped_data_df(leagues_page[\"drafts\"])\n",
    "            leagues_df_list.append(leagues_page_df)\n",
    "\n",
    "        leagues_df = pd.concat(leagues_df_list)\n",
    "\n",
    "        return leagues_df\n",
    "\n",
    "    def _create_json_leagues(self, url_base: str) -> dict:\n",
    "        \"\"\"\n",
    "        Loops through all the different pages that contain the league level data\n",
    "        and stores each as an entry in a dict\n",
    "        \"\"\"\n",
    "\n",
    "        url_exists = True\n",
    "        i = 1\n",
    "        leagues_json_dict = {}\n",
    "        while url_exists:\n",
    "            if i == 1:\n",
    "                url = url_base\n",
    "            else:\n",
    "                url = url_base + \"?page=\" + str(i)\n",
    "\n",
    "            leagues = self.read_in_site_data(url, headers=self.auth_header)\n",
    "\n",
    "            if len(leagues[\"drafts\"]) > 0:\n",
    "                leagues_json_dict[\"page_\" + str(i)] = leagues\n",
    "            else:\n",
    "                url_exists = False\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return leagues_json_dict\n",
    "\n",
    "    def _create_df_tourney_league_ids(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Tournament leagues (i.e. Puppy 1, Puppy 2, etc.) require the ID of the\n",
    "        tourney in order to find all entries in it - This creates of all tourney\n",
    "        IDs that has at least one entry\n",
    "        \"\"\"\n",
    "\n",
    "        json_tourney_league_ids = self.read_in_site_data(\n",
    "            self.url_tourney_league_ids, headers=self.auth_header\n",
    "        )\n",
    "        scraped_data = json_tourney_league_ids[\"tournament_rounds\"]\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(scraped_data)\n",
    "\n",
    "        # Pulling out the 'id' from the 'tournament' dict in case this is whats needed\n",
    "        tournament_col = initial_scraped_df[\"tournament\"].to_list()\n",
    "        tournament_df = self.create_scraped_data_df(tournament_col)\n",
    "        tournament_df.rename(columns={\"id\": \"tournament_id\"}, inplace=True)\n",
    "        tournament_df = tournament_df[\"tournament_id\"]\n",
    "\n",
    "        initial_scraped_df.drop([\"tournament\"], axis=1, inplace=True)\n",
    "        final_df = initial_scraped_df.join(tournament_df)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def _create_league_urls(self, tourney_league_ids: list = None) -> list:\n",
    "        \"\"\"\n",
    "        Creates a list of all the URLs that contain entries\n",
    "        \"\"\"\n",
    "        \n",
    "        if tourney_league_ids is None:\n",
    "            tourney_league_ids = list(self._create_df_tourney_league_ids()[\"id\"])\n",
    "\n",
    "        base_url = \"https://api.underdogfantasy.com/v1/user/tournament_rounds/\"\n",
    "        tourney_league_urls = []\n",
    "        for tourney_league_id in tourney_league_ids:\n",
    "            tourney_league_url = base_url + tourney_league_id + \"/drafts\"\n",
    "            tourney_league_urls.append(tourney_league_url)\n",
    "\n",
    "        tourney_league_urls.append(self.url_base_leagues)\n",
    "\n",
    "        return tourney_league_urls\n",
    "\n",
    "\n",
    "class ContestRefs(BaseData):\n",
    "    \"\"\" \n",
    "    Compiles all major contest related data into dataframes.\n",
    "    Note that this includes contests specific to a user (e.g. completed\n",
    "    slates, settled slates, etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bearer_token: str, clear_json_attrs: bool = True):\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs, slate_id=None)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "\n",
    "        self.url_slates_available = (\n",
    "            'https://stats.underdogfantasy.com/v1/sports/nfl/slates'\n",
    "        )\n",
    "        self.url_slates_completed = (\n",
    "            'https://api.underdogfantasy.com/v2/user/completed_slates'\n",
    "        )\n",
    "        self.url_slates_settled = (\n",
    "            'https://api.underdogfantasy.com/v1/user/sports/nfl/settled_slates'\n",
    "        )\n",
    "        self.url_scoring_types = (\n",
    "            'https://stats.underdogfantasy.com/v1/scoring_types'\n",
    "        )\n",
    "        self.url_contest_styles = (\n",
    "            'https://stats.underdogfantasy.com/v1/contest_styles'\n",
    "        )\n",
    "\n",
    "        self.df_slates_available = None\n",
    "        self.df_slates_completed = None\n",
    "        self.df_slates_settled = None\n",
    "        self.df_scoring_types = None\n",
    "        self.df_contest_styles = None\n",
    "\n",
    "        self.json = {}\n",
    "\n",
    "    def create_df_slates_available(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a slate level df of all slates that are available to \n",
    "        draft in.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._create_df_slates(\n",
    "            self.url_slates_available, 'slates_available',\n",
    "            headers=headers, clear_json=clear_json\n",
    "        )\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_slates_available = df\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_slates_completed(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a slate level df of all slates that are completed.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._create_df_slates(\n",
    "            self.url_slates_completed, 'slates_completed',\n",
    "            headers=headers, clear_json=clear_json\n",
    "        )\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_slates_completed = df\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_slates_settled(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a slate level df of all slates that are settled.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._create_df_slates(\n",
    "            self.url_slates_settled, 'slates_settled',\n",
    "            headers=headers, clear_json=clear_json\n",
    "        )\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_slates_settled = df\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_scoring_types(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a scoring type level df with the scoring types of all existing\n",
    "        NFL contests.\n",
    "\n",
    "        Notes:\n",
    "            - This is needed to automate the \"appearances\" (i.e. draft rank)\n",
    "            pull which uses the id as part of the url string\n",
    "            - 'display_stats' contains more descriptive information about each\n",
    "            scoring_type, but that data isn't needed now and would take some\n",
    "            time to pull out and structure.\n",
    "        \"\"\"\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "        \n",
    "        self.json['scoring_types'] = self.read_in_site_data(\n",
    "            self.url_scoring_types, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        df = self.create_scraped_data_df(self.json['scoring_types'][\"scoring_types\"])\n",
    "\n",
    "        df = df.loc[df['sport_id'] == 'NFL']\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_scoring_types = df\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json['scoring_types']\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_contest_styles(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "        \n",
    "        self.json['contest_styles'] = self.read_in_site_data(\n",
    "            self.url_contest_styles, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        df = self.create_scraped_data_df(self.json['contest_styles'][\"contest_styles\"])\n",
    "\n",
    "        df = df.loc[df['sport_id'] == 'NFL']\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_contest_styles = df\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json['contest_styles'] \n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_slate_ids(self, slate_type: str):\n",
    "        \"\"\"\n",
    "        Returns a list that contains each slate id for the slate_type.\n",
    "        slate_type must be 'available', 'completed', or 'settled'.\n",
    "        \"\"\"\n",
    "\n",
    "        attr = 'df_slates_' + slate_type.strip()\n",
    "        method_name = 'create_df_slates_' + slate_type.strip()\n",
    "\n",
    "        # NEED TO DOUBLE CHECK THIS - \n",
    "        if self.__dict__[attr] is None:\n",
    "            df = getattr(self, method_name)()\n",
    "        else:\n",
    "            df = self.__dict__[attr]\n",
    "\n",
    "        slates = list(df['id'])\n",
    "\n",
    "        return slates        \n",
    "\n",
    "    def _create_df_slates(self, url_slate: str, slate_type: str,\n",
    "        headers: dict=None, clear_json: bool=False\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "        Helper method that can be used to create a df for any slate type.\n",
    "        \"\"\"\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "        \n",
    "        self.json[slate_type] = self.read_in_site_data(\n",
    "            url_slate, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        df = self.create_scraped_data_df(self.json[slate_type][\"slates\"])\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json[slate_type]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def create_underdog_df_dict(bearer_token: str, sleep_time: int = 0) -> dict:\n",
    "    \"\"\"Creates a dictionary of dfs containing the most relevant UD data\"\"\"\n",
    "\n",
    "    ref_data = ReferenceData()\n",
    "    ref_data.build_all_dfs()\n",
    "\n",
    "    user_data = UserData(bearer_token)\n",
    "    user_data.build_all_dfs()\n",
    "    league_ids = list(user_data.df_all_leagues[\"id\"])\n",
    "\n",
    "    league_data = LeagueData(league_ids, bearer_token)\n",
    "    league_data.build_all_dfs(sleep_time=sleep_time)\n",
    "\n",
    "    df_players_master = ref_data.df_players_master\n",
    "    df_player_scores = ref_data.df_player_scores\n",
    "\n",
    "    player_vars = [\n",
    "        \"appearance_id\",\n",
    "        \"player_id\",\n",
    "        \"position\",\n",
    "        \"team_name\",\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "    ]\n",
    "    df_drafts = pd.merge(\n",
    "        league_data.df_drafts,\n",
    "        df_players_master[player_vars],\n",
    "        on=\"appearance_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_weekly_scores = league_data.df_weekly_scores\n",
    "\n",
    "    final_dict = {\n",
    "        \"df_players_master\": df_players_master,\n",
    "        \"df_player_scores\": df_player_scores,\n",
    "        \"df_drafts\": df_drafts,\n",
    "        \"df_weekly_scores\": df_weekly_scores,\n",
    "        \"df_league_info\": user_data.df_all_leagues,\n",
    "    }\n",
    "\n",
    "    return final_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearer eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI0ZWNkMDVmZi1kYTExLTQwY2UtYTYwNS05ZDVmZjZlMGMwODciLCJzdWIiOiIwMzcxNzEzMS1lMDUzLTQ1MWQtOWJlNi0wOTc1NWY1ODc1YWUiLCJzY3AiOiJ1c2VyIiwiYXVkIjpudWxsLCJpYXQiOjE2NzY3Mzg3OTUsImV4cCI6MTY3OTM2ODU0MX0.GX5wdBf7SVM8eVuBAYnBObz6gJntj8FEn9_bzLSDo50\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "### Variables to change ###\n",
    "chromedriver_path = \"/usr/bin/chromedriver\"\n",
    "username = input(\"Enter Underdog username: \")\n",
    "password = getpass.getpass()\n",
    "\n",
    "### Keep as is ###\n",
    "url = \"https://underdogfantasy.com/lobby\"\n",
    "bearer_token = pull_bearer_token(url, chromedriver_path, username, password)\n",
    "\n",
    "print(bearer_token)\n",
    "\n",
    "### Pull all major UD data elements ###\n",
    "# underdog_data = create_underdog_df_dict(bearer_token, sleep_time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ContestRefs(BaseData):\n",
    "    \"\"\" \n",
    "    Compiles all major contest related data into dataframes.\n",
    "    Note that this includes contests specific to a user (e.g. completed\n",
    "    slates, settled slates, etc.)    \n",
    "    \"\"\"\n",
    "\n",
    "    url_slates_available = (\n",
    "        'https://stats.underdogfantasy.com/v1/sports/nfl/slates'\n",
    "    )\n",
    "    url_slates_completed = (\n",
    "        'https://api.underdogfantasy.com/v2/user/completed_slates'\n",
    "    )\n",
    "    url_slates_settled = (\n",
    "        'https://api.underdogfantasy.com/v1/user/sports/nfl/settled_slates'\n",
    "    )\n",
    "    url_scoring_types = (\n",
    "        'https://stats.underdogfantasy.com/v1/scoring_types'\n",
    "    )\n",
    "    url_contest_styles = (\n",
    "        'https://stats.underdogfantasy.com/v1/contest_styles'\n",
    "    )   \n",
    "\n",
    "    def __init__(self, bearer_token: str, clear_json_attrs: bool = True):\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs, slate_id=None)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "\n",
    "        self.df_slates_available = None\n",
    "        self.df_slates_completed = None\n",
    "        self.df_slates_settled = None\n",
    "        self.df_scoring_types = None\n",
    "        self.df_contest_styles = None\n",
    "\n",
    "        self.json = {}\n",
    "\n",
    "    def create_df_slates_available(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a slate level df of all slates that are available to \n",
    "        draft in.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._create_df_slates(\n",
    "            ContestRefs.url_slates_available, 'slates_available',\n",
    "            headers=headers, clear_json=clear_json\n",
    "        )\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_slates_available = df\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_slates_completed(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a slate level df of all slates that are completed.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._create_df_slates(\n",
    "            ContestRefs.url_slates_completed, 'slates_completed',\n",
    "            headers=headers, clear_json=clear_json\n",
    "        )\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_slates_completed = df\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_slates_settled(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a slate level df of all slates that are settled.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._create_df_slates(\n",
    "            ContestRefs.url_slates_settled, 'slates_settled',\n",
    "            headers=headers, clear_json=clear_json\n",
    "        )\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_slates_settled = df\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_scoring_types(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a scoring type level df with the scoring types of all existing\n",
    "        NFL contests.\n",
    "\n",
    "        Notes:\n",
    "            - This is needed to automate the \"appearances\" (i.e. draft rank)\n",
    "            pull which uses the id as part of the url string\n",
    "            - 'display_stats' contains more descriptive information about each\n",
    "            scoring_type, but that data isn't needed now and would take some\n",
    "            time to pull out and structure.\n",
    "        \"\"\"\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "        \n",
    "        self.json['scoring_types'] = self.read_in_site_data(\n",
    "            ContestRefs.url_scoring_types, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        df = self.create_scraped_data_df(self.json['scoring_types'][\"scoring_types\"])\n",
    "\n",
    "        df = df.loc[df['sport_id'] == 'NFL']\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_scoring_types = df\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json['scoring_types']\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_df_contest_styles(self, headers: dict=None, clear_json: bool=False,\n",
    "    update_attr: bool=False) -> pd.DataFrame:\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "        \n",
    "        self.json['contest_styles'] = self.read_in_site_data(\n",
    "            ContestRefs.url_contest_styles, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        df = self.create_scraped_data_df(self.json['contest_styles'][\"contest_styles\"])\n",
    "\n",
    "        df = df.loc[df['sport_id'] == 'NFL']\n",
    "\n",
    "        if update_attr:\n",
    "            self.df_contest_styles = df\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json['contest_styles'] \n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_slate_ids(self, slate_type: str):\n",
    "        \"\"\"\n",
    "        Returns a list that contains each slate id for the slate_type.\n",
    "        slate_type must be 'available', 'completed', or 'settled'.\n",
    "        \"\"\"\n",
    "\n",
    "        attr = 'df_slates_' + slate_type.strip()\n",
    "        method_name = 'create_df_slates_' + slate_type.strip()\n",
    "\n",
    "        if self.__dict__[attr] is None:\n",
    "            df = getattr(self, method_name)()\n",
    "        else:\n",
    "            df = self.__dict__[attr]\n",
    "\n",
    "        slates = list(df['id'])\n",
    "\n",
    "        return slates        \n",
    "\n",
    "    def _create_df_slates(self, url_slate: str, slate_type: str,\n",
    "        headers: dict=None, clear_json: bool=False\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "        Helper method that can be used to create a df for any slate type.\n",
    "        \"\"\"\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "        \n",
    "        self.json[slate_type] = self.read_in_site_data(\n",
    "            url_slate, headers=self.auth_header\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            df = self.create_scraped_data_df(self.json[slate_type][\"slates\"])\n",
    "        except IndexError:\n",
    "            print(f'No data found in {url_slate} - no df will be returned')\n",
    "            df = None\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json[slate_type]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class UserData(BaseData):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        bearer_token: str,\n",
    "        # slate_id: str,\n",
    "        clear_json_attrs: bool=True):\n",
    "        \"\"\"\n",
    "        Note: This requires the user-agent header - Should be able to grab this\n",
    "        with the bearer token, but hard coding for now\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "\n",
    "        self.contest_refs = ContestRefs(bearer_token, clear_json_attrs=clear_json_attrs)\n",
    "\n",
    "        self.slate_id = '87a5caba-d5d7-46d9-a798-018d7c116213'\n",
    "\n",
    "        self.url_live_leagues = (\n",
    "            'https://api.underdogfantasy.com/v3/user/active_drafts'\n",
    "        )\n",
    "        # self.url_base_leagues = (\n",
    "        #     \"https://api.underdogfantasy.com/v2/user/slates/\"\n",
    "        #     + self.slate_id\n",
    "        #     + \"/live_drafts\"\n",
    "        # )\n",
    "        # self.url_base_leagues = (\n",
    "        #     'https://api.underdogfantasy.com/v2/user/slates/' \n",
    "        #     + self.slate_id \n",
    "        #     + '/completed_drafts'\n",
    "        # )\n",
    "        self.url_base_leagues = (\n",
    "            'https://api.underdogfantasy.com/v2/user/slates/' \n",
    "            + self.slate_id \n",
    "            + '/settled_drafts'\n",
    "        )\n",
    "        self.url_tourney_league_ids = (\n",
    "            \"https://api.underdogfantasy.com/v1/user/slates/\"\n",
    "            + self.slate_id\n",
    "            + \"/tournament_rounds\"\n",
    "        )\n",
    "\n",
    "        self.json_leagues = {}\n",
    "\n",
    "        self.df_all_leagues = pd.DataFrame()\n",
    "\n",
    "    def create_df_all_leagues(self, league_urls: list=None) -> pd.DataFrame:\n",
    "        if league_urls is None:\n",
    "            league_urls = self._create_league_urls()\n",
    "\n",
    "        leagues = []\n",
    "        for i, league_url in enumerate(league_urls):\n",
    "            df = self._create_df_leagues(league_url, \"league_\" + str(i + 1))\n",
    "            leagues.append(df)\n",
    "\n",
    "        df_all_leagues = pd.concat(leagues)\n",
    "        df_all_leagues.reset_index(inplace=True)\n",
    "        df_all_leagues.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "        return df_all_leagues\n",
    "\n",
    "    def _create_df_leagues(self, url_base: str, json_leagues_key: str) -> pd.DataFrame:\n",
    "        self.json_leagues[json_leagues_key] = self._create_json_leagues(url_base)\n",
    "        scraped_data = self.json_leagues[json_leagues_key]\n",
    "\n",
    "        leagues_df_list = []\n",
    "        for leagues_page in scraped_data.values():\n",
    "            leagues_page_df = self.create_scraped_data_df(leagues_page[\"drafts\"])\n",
    "            leagues_df_list.append(leagues_page_df)\n",
    "\n",
    "        leagues_df = pd.concat(leagues_df_list)\n",
    "\n",
    "        return leagues_df\n",
    "\n",
    "    def _create_json_leagues(self, url_base: str) -> dict:\n",
    "        \"\"\"\n",
    "        Loops through all the different pages that contain the league level data\n",
    "        and stores each as an entry in a dict\n",
    "        \"\"\"\n",
    "\n",
    "        url_exists = True\n",
    "        i = 1\n",
    "        leagues_json_dict = {}\n",
    "        while url_exists:\n",
    "            if i == 1:\n",
    "                url = url_base\n",
    "            else:\n",
    "                url = url_base + \"?page=\" + str(i)\n",
    "\n",
    "            leagues = self.read_in_site_data(url, headers=self.auth_header)\n",
    "\n",
    "            if len(leagues[\"drafts\"]) > 0:\n",
    "                leagues_json_dict[\"page_\" + str(i)] = leagues\n",
    "            else:\n",
    "                url_exists = False\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return leagues_json_dict\n",
    "\n",
    "    def _create_df_tourney_league_ids(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Tournament leagues (i.e. Puppy 1, Puppy 2, etc.) require the ID of the\n",
    "        tourney in order to find all entries in it - This creates of all tourney\n",
    "        IDs that has at least one entry\n",
    "        \"\"\"\n",
    "\n",
    "        json_tourney_league_ids = self.read_in_site_data(\n",
    "            self.url_tourney_league_ids, headers=self.auth_header\n",
    "        )\n",
    "        scraped_data = json_tourney_league_ids[\"tournament_rounds\"]\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(scraped_data)\n",
    "\n",
    "        # Pulling out the 'id' from the 'tournament' dict in case this is whats needed\n",
    "        tournament_col = initial_scraped_df[\"tournament\"].to_list()\n",
    "        tournament_df = self.create_scraped_data_df(tournament_col)\n",
    "        tournament_df.rename(columns={\"id\": \"tournament_id\"}, inplace=True)\n",
    "        tournament_df = tournament_df[\"tournament_id\"]\n",
    "\n",
    "        initial_scraped_df.drop([\"tournament\"], axis=1, inplace=True)\n",
    "        final_df = initial_scraped_df.join(tournament_df)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def _create_league_urls(self, tourney_league_ids: list = None) -> list:\n",
    "        \"\"\"\n",
    "        Creates a list of all the URLs that contain entries\n",
    "        \"\"\"\n",
    "        \n",
    "        if tourney_league_ids is None:\n",
    "            tourney_league_ids = list(self._create_df_tourney_league_ids()[\"id\"])\n",
    "\n",
    "        base_url = \"https://api.underdogfantasy.com/v1/user/tournament_rounds/\"\n",
    "        tourney_league_urls = []\n",
    "        for tourney_league_id in tourney_league_ids:\n",
    "            tourney_league_url = base_url + tourney_league_id + \"/drafts\"\n",
    "            tourney_league_urls.append(tourney_league_url)\n",
    "\n",
    "        tourney_league_urls.append(self.url_base_leagues)\n",
    "\n",
    "        return tourney_league_urls\n",
    "\n",
    "\n",
    "class Drafts(BaseData):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        bearer_token: str,\n",
    "        slate: Slate,\n",
    "        clear_json_attrs: bool=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Note: This requires the user-agent header - Should be able to grab this\n",
    "        with the bearer token, but hard coding for now\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "\n",
    "        self.slate = slate\n",
    "\n",
    "        url_suffix = f'/{self.slate.slate_type}_drafts'\n",
    "        self.url_base_leagues = (\n",
    "            \"https://api.underdogfantasy.com/v2/user/slates/\"\n",
    "            + self.slate.id\n",
    "            + url_suffix\n",
    "        )\n",
    "        self.url_tourney_league_ids = (\n",
    "            \"https://api.underdogfantasy.com/v1/user/slates/\"\n",
    "            + self.slate.id\n",
    "            + \"/tournament_rounds\"\n",
    "        )\n",
    "\n",
    "        self.url_live_leagues = (\n",
    "            'https://api.underdogfantasy.com/v3/user/active_drafts'\n",
    "        )\n",
    "        # self.url_base_leagues = (\n",
    "        #     \"https://api.underdogfantasy.com/v2/user/slates/\"\n",
    "        #     + self.slate_id\n",
    "        #     + \"/live_drafts\"\n",
    "        # )\n",
    "        # self.url_base_leagues = (\n",
    "        #     'https://api.underdogfantasy.com/v2/user/slates/' \n",
    "        #     + self.slate_id \n",
    "        #     + '/completed_drafts'\n",
    "        # )\n",
    "        # self.url_base_leagues = (\n",
    "        #     'https://api.underdogfantasy.com/v2/user/slates/' \n",
    "        #     + self.slate_id \n",
    "        #     + '/settled_drafts'\n",
    "        # )\n",
    "\n",
    "        self.json_leagues = {}\n",
    "\n",
    "        self.df_all_leagues = pd.DataFrame()\n",
    "\n",
    "    def create_df_all_leagues(self, league_urls: list=None) -> pd.DataFrame:\n",
    "        if league_urls is None:\n",
    "            league_urls = self.get_league_urls()\n",
    "\n",
    "        leagues = []\n",
    "        for i, league_url in enumerate(league_urls):\n",
    "            df = self._create_df_leagues(league_url, \"league_\" + str(i + 1))\n",
    "            leagues.append(df)\n",
    "\n",
    "        df_all_leagues = pd.concat(leagues)\n",
    "        df_all_leagues.reset_index(inplace=True)\n",
    "        df_all_leagues.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "        return df_all_leagues\n",
    "\n",
    "    def get_league_urls(self) -> list:\n",
    "        \"\"\" \n",
    "        Creates a list of all urls which store draft level data for the slate\n",
    "        \"\"\"\n",
    "\n",
    "        if self.slate.tournament_draft_count > 0:\n",
    "            tourney_league_urls = self._create_tourney_league_urls()\n",
    "        else:\n",
    "            tourney_league_urls = []\n",
    "\n",
    "        if self.slate.draft_count > 0:\n",
    "            base_league_url = [self.url_base_leagues]\n",
    "        else:\n",
    "            base_league_url = []\n",
    "\n",
    "        urls = base_league_url + tourney_league_urls\n",
    "\n",
    "        return urls        \n",
    "\n",
    "    def _create_df_leagues(self, url_base: str, json_leagues_key: str) -> pd.DataFrame:\n",
    "        self.json_leagues[json_leagues_key] = self._create_json_leagues(url_base)\n",
    "        scraped_data = self.json_leagues[json_leagues_key]\n",
    "\n",
    "        leagues_df_list = []\n",
    "        for leagues_page in scraped_data.values():\n",
    "            leagues_page_df = self.create_scraped_data_df(leagues_page[\"drafts\"])\n",
    "            leagues_df_list.append(leagues_page_df)\n",
    "\n",
    "        leagues_df = pd.concat(leagues_df_list)\n",
    "\n",
    "        return leagues_df\n",
    "\n",
    "    def _create_json_leagues(self, url_base: str) -> dict:\n",
    "        \"\"\"\n",
    "        Loops through all the different pages that contain the league level data\n",
    "        and stores each as an entry in a dict\n",
    "        \"\"\"\n",
    "\n",
    "        url_exists = True\n",
    "        i = 1\n",
    "        leagues_json_dict = {}\n",
    "        while url_exists:\n",
    "            if i == 1:\n",
    "                url = url_base\n",
    "            else:\n",
    "                url = url_base + \"?page=\" + str(i)\n",
    "\n",
    "            leagues = self.read_in_site_data(url, headers=self.auth_header)\n",
    "\n",
    "            if len(leagues[\"drafts\"]) > 0:\n",
    "                leagues_json_dict[\"page_\" + str(i)] = leagues\n",
    "            else:\n",
    "                url_exists = False\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return leagues_json_dict\n",
    "\n",
    "    def _create_df_tourney_league_ids(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Tournament leagues (i.e. Puppy 1, Puppy 2, etc.) require the ID of the\n",
    "        tourney in order to find all entries in it - This creates of all tourney\n",
    "        IDs that has at least one entry\n",
    "        \"\"\"\n",
    "\n",
    "        json_tourney_league_ids = self.read_in_site_data(\n",
    "            self.url_tourney_league_ids, headers=self.auth_header\n",
    "        )\n",
    "        scraped_data = json_tourney_league_ids[\"tournament_rounds\"]\n",
    "\n",
    "        initial_scraped_df = self.create_scraped_data_df(scraped_data)\n",
    "\n",
    "        # Pulling out the 'id' from the 'tournament' dict in case this is whats needed\n",
    "        tournament_col = initial_scraped_df[\"tournament\"].to_list()\n",
    "        tournament_df = self.create_scraped_data_df(tournament_col)\n",
    "        tournament_df.rename(columns={\"id\": \"tournament_id\"}, inplace=True)\n",
    "        tournament_df = tournament_df[\"tournament_id\"]\n",
    "\n",
    "        initial_scraped_df.drop([\"tournament\"], axis=1, inplace=True)\n",
    "        final_df = initial_scraped_df.join(tournament_df)\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def _create_tourney_league_urls(self) -> list:\n",
    "        \"\"\"\n",
    "        Creates a list of all the URLs that contain entries\n",
    "        \"\"\"\n",
    "        \n",
    "        tourney_league_ids = list(self._create_df_tourney_league_ids()[\"id\"])\n",
    "\n",
    "        base_url = \"https://api.underdogfantasy.com/v1/user/tournament_rounds/\"\n",
    "        tourney_league_urls = []\n",
    "        for tourney_league_id in tourney_league_ids:\n",
    "            tourney_league_url = base_url + tourney_league_id + \"/drafts\"\n",
    "\n",
    "            tourney_league_urls.append(tourney_league_url)\n",
    "\n",
    "        return tourney_league_urls\n",
    "\n",
    "\n",
    "class Slates(BaseData):\n",
    "    \"\"\" \n",
    "    Compiles all available and completed slates for a specific slate type. \n",
    "    \"\"\"\n",
    "\n",
    "    url_slates_available = (\n",
    "        'https://stats.underdogfantasy.com/v1/sports/nfl/slates'\n",
    "    )\n",
    "    url_slates_completed = (\n",
    "        'https://api.underdogfantasy.com/v2/user/completed_slates'\n",
    "    )\n",
    "    url_slates_settled = (\n",
    "        'https://api.underdogfantasy.com/v1/user/sports/nfl/settled_slates'\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bearer_token: str,\n",
    "        slate_type: str,\n",
    "        clear_json_attrs: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        slate_type must be 'available', 'completed', or 'settled'\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(clear_json_attrs=clear_json_attrs, slate_id=None)\n",
    "\n",
    "        self.auth_header['authorization'] = bearer_token\n",
    "        self.slate_type = slate_type\n",
    "\n",
    "        self.df_slates = None\n",
    "        self.slates = []\n",
    "\n",
    "        self.json = {}\n",
    "\n",
    "    def create_df_slates(self, headers: dict=None, clear_json: bool=False\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "        Creates df of all the slates found.\n",
    "        \"\"\"\n",
    "\n",
    "        if headers is None:\n",
    "            headers=self.auth_header\n",
    "\n",
    "        url = self._get_url()\n",
    "        \n",
    "        self.json = self.read_in_site_data(url, headers=self.auth_header)\n",
    "\n",
    "        try:\n",
    "            df = self.create_scraped_data_df(self.json[\"slates\"])\n",
    "        except IndexError:\n",
    "            print(f'No data found in {url} - no df will be returned')\n",
    "            df = None\n",
    "\n",
    "        self.slates = self._create_slates(df)\n",
    "\n",
    "        if clear_json:\n",
    "            del self.json\n",
    "\n",
    "        return df       \n",
    "\n",
    "    def _get_url(self) -> str:\n",
    "        \"\"\"\n",
    "        Selects the url to be used based on the slate_type.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.slate_type == 'available':\n",
    "            url = Slates.url_slates_available\n",
    "        elif self.slate_type == 'completed':\n",
    "            url = Slates.url_slates_completed\n",
    "        elif self.slate_type == 'settled':\n",
    "            url = Slates.url_slates_settled\n",
    "\n",
    "        return url\n",
    "\n",
    "    def _create_slates(self, df_slates: pd.DataFrame) -> list:\n",
    "        \"\"\" \n",
    "        Creates a list of Slate objects.\n",
    "        \"\"\"\n",
    "\n",
    "        slates = []\n",
    "        for i in range(len(df_slates)):\n",
    "            slate = Slate(df_slates.iloc[i], self.slate_type)\n",
    "\n",
    "            slates.append(slate)\n",
    "\n",
    "        return slates\n",
    "\n",
    "\n",
    "class Slate:\n",
    "\n",
    "    def __init__(self, df_slate: pd.Series, slate_type):\n",
    "        self.id = df_slate['id']\n",
    "        self.description = df_slate['description']\n",
    "        self.title = df_slate['title']\n",
    "        self.draft_count = df_slate['draft_count']\n",
    "        self.tournament_draft_count = df_slate['tournament_draft_count']\n",
    "        self.slate_type = slate_type\n",
    "\n",
    "# site = ContestRefs(bearer_token)\n",
    "# leagues = LeagueData(['1eafd8e3-c601-4363-896d-41050d37127c'], bearer_token)\n",
    "# user = UserData(bearer_token)\n",
    "\n",
    "slates = Slates(bearer_token, 'settled')\n",
    "\n",
    "slates.create_df_slates()\n",
    "slate = slates.slates[5]\n",
    "\n",
    "user = Drafts(bearer_token, slate)\n",
    "\n",
    "# user.slate.slate_type\n",
    "len(user.create_df_all_leagues())\n",
    "# user.get_league_urls()\n",
    "# slate.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>contest_style_ids</th>\n",
       "      <th>cutoff_at</th>\n",
       "      <th>description</th>\n",
       "      <th>draft_count</th>\n",
       "      <th>draft_pool_draft_count</th>\n",
       "      <th>fees</th>\n",
       "      <th>game_count</th>\n",
       "      <th>lobby_hidden</th>\n",
       "      <th>payouts</th>\n",
       "      <th>sport_id</th>\n",
       "      <th>start_at</th>\n",
       "      <th>title</th>\n",
       "      <th>tournament_draft_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f659a9be-fd34-4a1e-9c43-0816267e603d</td>\n",
       "      <td>[9e62863e-1b29-53e8-8aca-2aae06aaac5f]</td>\n",
       "      <td>2022-09-09T00:12:00Z</td>\n",
       "      <td>NFL 2022 Season</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2022-09-09T00:20:00Z</td>\n",
       "      <td>2022 Season</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53ec8ef2-e1f2-401c-9a83-c0838d6a2b77</td>\n",
       "      <td>[502f3754-7bf4-4cc4-baf3-ea7d93f09318]</td>\n",
       "      <td>2023-02-12T23:22:00Z</td>\n",
       "      <td>1 - games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2023-02-12T23:30:00Z</td>\n",
       "      <td>KC @ PHI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9782da47-bc39-4dc6-accd-42df33bd7b24</td>\n",
       "      <td>[9e62863e-1b29-53e8-8aca-2aae06aaac5f]</td>\n",
       "      <td>2022-12-15T04:52:00Z</td>\n",
       "      <td>NFL 2022 Season: Week 15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2022-12-15T05:00:00Z</td>\n",
       "      <td>2022 Season</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fbc16cb-7ccc-4f53-9b12-330c07967533</td>\n",
       "      <td>[9e62863e-1b29-53e8-8aca-2aae06aaac5f]</td>\n",
       "      <td>2022-09-08T03:52:00Z</td>\n",
       "      <td>NFL 2022 Season: Week 1 - 14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2022-09-08T04:00:00Z</td>\n",
       "      <td>2022 Season</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87a5caba-d5d7-46d9-a798-018d7c116213</td>\n",
       "      <td>[9e62863e-1b29-53e8-8aca-2aae06aaac5f]</td>\n",
       "      <td>2021-09-10T00:12:00Z</td>\n",
       "      <td>2021 NFL Best Ball</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2021-09-10T00:20:00Z</td>\n",
       "      <td>2021 Best Ball Season</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c9467f03-0fda-4c2b-a86d-b518faa2a265</td>\n",
       "      <td>[9e62863e-1b29-53e8-8aca-2aae06aaac5f]</td>\n",
       "      <td>2021-12-17T01:12:00Z</td>\n",
       "      <td>Week 15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2021-12-17T01:20:00Z</td>\n",
       "      <td>2021 Best Ball Season</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  f659a9be-fd34-4a1e-9c43-0816267e603d   \n",
       "1  53ec8ef2-e1f2-401c-9a83-c0838d6a2b77   \n",
       "2  9782da47-bc39-4dc6-accd-42df33bd7b24   \n",
       "3  5fbc16cb-7ccc-4f53-9b12-330c07967533   \n",
       "4  87a5caba-d5d7-46d9-a798-018d7c116213   \n",
       "5  c9467f03-0fda-4c2b-a86d-b518faa2a265   \n",
       "\n",
       "                        contest_style_ids             cutoff_at  \\\n",
       "0  [9e62863e-1b29-53e8-8aca-2aae06aaac5f]  2022-09-09T00:12:00Z   \n",
       "1  [502f3754-7bf4-4cc4-baf3-ea7d93f09318]  2023-02-12T23:22:00Z   \n",
       "2  [9e62863e-1b29-53e8-8aca-2aae06aaac5f]  2022-12-15T04:52:00Z   \n",
       "3  [9e62863e-1b29-53e8-8aca-2aae06aaac5f]  2022-09-08T03:52:00Z   \n",
       "4  [9e62863e-1b29-53e8-8aca-2aae06aaac5f]  2021-09-10T00:12:00Z   \n",
       "5  [9e62863e-1b29-53e8-8aca-2aae06aaac5f]  2021-12-17T01:12:00Z   \n",
       "\n",
       "                    description  draft_count  draft_pool_draft_count   fees  \\\n",
       "0               NFL 2022 Season           30                       0   90.0   \n",
       "1                     1 - games            5                       0   15.0   \n",
       "2      NFL 2022 Season: Week 15            0                       0    0.0   \n",
       "3  NFL 2022 Season: Week 1 - 14            0                       0   96.0   \n",
       "4            2021 NFL Best Ball           29                       0  203.0   \n",
       "5                       Week 15            0                       0    0.0   \n",
       "\n",
       "   game_count  lobby_hidden payouts sport_id              start_at  \\\n",
       "0         NaN         False   131.0      NFL  2022-09-09T00:20:00Z   \n",
       "1         1.0         False    15.0      NFL  2023-02-12T23:30:00Z   \n",
       "2         NaN         False     1.0      NFL  2022-12-15T05:00:00Z   \n",
       "3         NaN         False    28.0      NFL  2022-09-08T04:00:00Z   \n",
       "4         NaN         False    71.0      NFL  2021-09-10T00:20:00Z   \n",
       "5         NaN         False     3.0      NFL  2021-12-17T01:20:00Z   \n",
       "\n",
       "                   title  tournament_draft_count  \n",
       "0            2022 Season                       0  \n",
       "1               KC @ PHI                       0  \n",
       "2            2022 Season                       4  \n",
       "3            2022 Season                      20  \n",
       "4  2021 Best Ball Season                      12  \n",
       "5  2021 Best Ball Season                       2  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_slates = slates.create_df_slates()\n",
    "\n",
    "# df_slates.iloc[0].to_dict()\n",
    "\n",
    "df_slates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14844/2157793516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "check = 5\n",
    "\n",
    "try:\n",
    "    for x in check:\n",
    "        print(x)\n",
    "except IndexError:\n",
    "    print('check this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>contest_style_ids</th>\n",
       "      <th>cutoff_at</th>\n",
       "      <th>description</th>\n",
       "      <th>game_count</th>\n",
       "      <th>lobby_hidden</th>\n",
       "      <th>sport_id</th>\n",
       "      <th>start_at</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b84244dc-aa63-4b62-bdd5-8fccd365c074</td>\n",
       "      <td>[978b95dd-7c25-467c-83c9-332d90a557a4]</td>\n",
       "      <td>2023-04-28T23:52:00Z</td>\n",
       "      <td>2023 Pre-Draft Best Ball</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2023-04-29T00:00:00Z</td>\n",
       "      <td>2023 Pre-Draft Best Ball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  b84244dc-aa63-4b62-bdd5-8fccd365c074   \n",
       "\n",
       "                        contest_style_ids             cutoff_at  \\\n",
       "0  [978b95dd-7c25-467c-83c9-332d90a557a4]  2023-04-28T23:52:00Z   \n",
       "\n",
       "                description game_count  lobby_hidden sport_id  \\\n",
       "0  2023 Pre-Draft Best Ball       None         False      NFL   \n",
       "\n",
       "               start_at                     title  \n",
       "0  2023-04-29T00:00:00Z  2023 Pre-Draft Best Ball  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site.create_df_slates_available()\n",
    "\n",
    "# site.df_slates_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>contest_style_ids</th>\n",
       "      <th>cutoff_at</th>\n",
       "      <th>description</th>\n",
       "      <th>game_count</th>\n",
       "      <th>lobby_hidden</th>\n",
       "      <th>sport_id</th>\n",
       "      <th>start_at</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b84244dc-aa63-4b62-bdd5-8fccd365c074</td>\n",
       "      <td>[978b95dd-7c25-467c-83c9-332d90a557a4]</td>\n",
       "      <td>2023-04-28T23:52:00Z</td>\n",
       "      <td>2023 Pre-Draft Best Ball</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2023-04-29T00:00:00Z</td>\n",
       "      <td>2023 Pre-Draft Best Ball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  b84244dc-aa63-4b62-bdd5-8fccd365c074   \n",
       "\n",
       "                        contest_style_ids             cutoff_at  \\\n",
       "0  [978b95dd-7c25-467c-83c9-332d90a557a4]  2023-04-28T23:52:00Z   \n",
       "\n",
       "                description game_count  lobby_hidden sport_id  \\\n",
       "0  2023 Pre-Draft Best Ball       None         False      NFL   \n",
       "\n",
       "               start_at                     title  \n",
       "0  2023-04-29T00:00:00Z  2023 Pre-Draft Best Ball  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_available = 'https://stats.underdogfantasy.com/v1/sports/nfl/slates'\n",
    "url_completed = 'https://api.underdogfantasy.com/v2/user/completed_slates'\n",
    "url_settled = 'https://api.underdogfantasy.com/v1/user/sports/nfl/settled_slates'\n",
    "\n",
    "url_st = 'https://stats.underdogfantasy.com/v1/scoring_types'\n",
    "\n",
    "auth_header = {\n",
    "    \"accept\": \"application/json\",    \n",
    "    \"authorization\": bearer_token,\n",
    "    \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) \\\n",
    "                        AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                        Chrome/99.0.4844.51 Safari/537.36\"\n",
    "}\n",
    "\n",
    "base = BaseData()\n",
    "\n",
    "data = base.read_in_site_data(url_available, headers=auth_header)\n",
    "# data = base.read_in_site_data(url_st)\n",
    "\n",
    "base.create_scraped_data_df(data['slates'])\n",
    "\n",
    "# data['slates'][0].keys()\n",
    "# data['scoring_types'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site.create_df_slates_completed(headers=auth_header)\n",
    "# site.create_df_scoring_types()\n",
    "# site.create_df_contest_styles()\n",
    "\n",
    "# df = site.create_df_contest_styles()\n",
    "\n",
    "# df.loc[df['status'] == 'active']\n",
    "\n",
    "\n",
    "# leagues.create_df_drafts()\n",
    "\n",
    "# user.create_df_all_leagues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drafts': [{'id': 'bf473ecd-e3b6-4777-86c5-35db00b34c1a', 'auto_pick_at': '2023-02-12T21:45:42Z', 'clock': 30, 'contest_style_id': '502f3754-7bf4-4cc4-baf3-ea7d93f09318', 'draft_at': '2023-02-12T21:45:12Z', 'draft_entry_id': '08ddbd4a-4053-447c-9e97-82fccca02f4c', 'draft_type': 'fast', 'entry_count': 2, 'entry_role': None, 'entry_style_id': '2e20d083-b067-4016-a6f3-1d7a9470d6d7', 'pick_count': 0, 'slate_id': '53ec8ef2-e1f2-401c-9a83-c0838d6a2b77', 'source': 'sit_and_go', 'source_entry_style_id': None, 'status': 'drafting', 'title': None, 'user_auto_pick': 'off', 'user_pick_order': 1}]}\n"
     ]
    }
   ],
   "source": [
    "# url = 'https://api.underdogfantasy.com/v2/drafts/5439a246-a197-42b3-a7bf-a0de1eda4a6d'\n",
    "\n",
    "# url = (\n",
    "#     \"https://api.underdogfantasy.com/v2/user/slates/\"\n",
    "#     + '53ec8ef2-e1f2-401c-9a83-c0838d6a2b77'\n",
    "#     + \"/live_drafts\"\n",
    "# )\n",
    "\n",
    "url = 'https://api.underdogfantasy.com/v3/user/active_drafts'\n",
    "\n",
    "user = UserData(bearer_token)\n",
    "\n",
    "active_drafts = user.read_in_site_data(url, user.auth_header)\n",
    "print(active_drafts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>auto_pick_at</th>\n",
       "      <th>clock</th>\n",
       "      <th>contest_style_id</th>\n",
       "      <th>draft_at</th>\n",
       "      <th>draft_entry_id</th>\n",
       "      <th>draft_type</th>\n",
       "      <th>entry_count</th>\n",
       "      <th>entry_role</th>\n",
       "      <th>entry_style_id</th>\n",
       "      <th>pick_count</th>\n",
       "      <th>slate_id</th>\n",
       "      <th>source</th>\n",
       "      <th>source_entry_style_id</th>\n",
       "      <th>status</th>\n",
       "      <th>title</th>\n",
       "      <th>user_auto_pick</th>\n",
       "      <th>user_pick_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bf473ecd-e3b6-4777-86c5-35db00b34c1a</td>\n",
       "      <td>2023-02-12T21:45:42Z</td>\n",
       "      <td>30</td>\n",
       "      <td>502f3754-7bf4-4cc4-baf3-ea7d93f09318</td>\n",
       "      <td>2023-02-12T21:45:12Z</td>\n",
       "      <td>08ddbd4a-4053-447c-9e97-82fccca02f4c</td>\n",
       "      <td>fast</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>2e20d083-b067-4016-a6f3-1d7a9470d6d7</td>\n",
       "      <td>0</td>\n",
       "      <td>53ec8ef2-e1f2-401c-9a83-c0838d6a2b77</td>\n",
       "      <td>sit_and_go</td>\n",
       "      <td>None</td>\n",
       "      <td>drafting</td>\n",
       "      <td>None</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id          auto_pick_at  clock  \\\n",
       "0  bf473ecd-e3b6-4777-86c5-35db00b34c1a  2023-02-12T21:45:42Z     30   \n",
       "\n",
       "                       contest_style_id              draft_at  \\\n",
       "0  502f3754-7bf4-4cc4-baf3-ea7d93f09318  2023-02-12T21:45:12Z   \n",
       "\n",
       "                         draft_entry_id draft_type  entry_count entry_role  \\\n",
       "0  08ddbd4a-4053-447c-9e97-82fccca02f4c       fast            2       None   \n",
       "\n",
       "                         entry_style_id  pick_count  \\\n",
       "0  2e20d083-b067-4016-a6f3-1d7a9470d6d7           0   \n",
       "\n",
       "                               slate_id      source source_entry_style_id  \\\n",
       "0  53ec8ef2-e1f2-401c-9a83-c0838d6a2b77  sit_and_go                  None   \n",
       "\n",
       "     status title user_auto_pick  user_pick_order  \n",
       "0  drafting  None            off                1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################## CODE FOR ACTIVE DRAFTS #############################\n",
    "\n",
    "# url = 'https://api.underdogfantasy.com/v3/user/active_drafts'\n",
    "\n",
    "# user = UserData(bearer_token)\n",
    "\n",
    "# active_drafts = user.read_in_site_data(url, user.auth_header)\n",
    "\n",
    "df = user.create_scraped_data_df(active_drafts['drafts'])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc4492b5efc155a9cdcda09d43a20d3fd18b0b2d151b680a1414de88ecead1b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
